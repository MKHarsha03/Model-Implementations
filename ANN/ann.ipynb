{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset from OpenML\n",
    "data = fetch_openml('mnist_784', version=1, parser='auto')\n",
    "X = data.data.astype(np.float32)\n",
    "y = data.target.astype(int)\n",
    "\n",
    "# Split dataset into training and test sets\n",
    "X, X_test, y, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode labels\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y = encoder.fit_transform(y.values.reshape(-1, 1))\n",
    "y_test = encoder.transform(y_test.values.reshape(-1, 1))\n",
    "\n",
    "def sigmoid(X):\n",
    "    return 1 / (1 + np.exp(-X))\n",
    "\n",
    "def relu(X):\n",
    "    return np.maximum(0, X)\n",
    "\n",
    "def relu_derivative(x):\n",
    "    return (x > 0).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.07220720235260465\n",
      "Epoch 10, Loss: 0.16477213735484578\n",
      "Epoch 20, Loss: 0.12035822248956236\n",
      "Epoch 30, Loss: 0.07472639312017305\n",
      "Epoch 40, Loss: 0.09078593887481874\n",
      "Epoch 50, Loss: 0.049184471285311136\n",
      "Epoch 60, Loss: 0.04755757600746576\n",
      "Epoch 70, Loss: 0.04236004335572294\n",
      "Epoch 80, Loss: 0.038000457881497425\n",
      "Epoch 90, Loss: 0.034442001819515976\n",
      "Training Accuracy: 91.67%\n",
      "Test Accuracy: 91.73%\n",
      "Predicted Labels: [8 4 8 7 7]\n"
     ]
    }
   ],
   "source": [
    "def ann(layers, lr, epochs, X, Y, X_test, y_test):\n",
    "    weights = [np.random.randn(layers[i], layers[i+1]) * 0.01 for i in range(len(layers) - 1)]\n",
    "    biases = [np.zeros((1, layers[i+1])) for i in range(len(layers) - 1)]\n",
    "\n",
    "    def forward(X):\n",
    "        activations = [X]\n",
    "        Z_values = []\n",
    "        for i in range(len(weights) - 1):\n",
    "            Z = np.dot(activations[-1], weights[i]) + biases[i]\n",
    "            Z_values.append(Z)\n",
    "            X = relu(Z)\n",
    "            activations.append(X)\n",
    "        Z_out = np.dot(activations[-1], weights[-1]) + biases[-1]\n",
    "        Z_values.append(Z_out)\n",
    "        output = sigmoid(Z_out)\n",
    "        activations.append(output)\n",
    "        return activations, Z_values\n",
    "\n",
    "    def backward(activations, Z_values, y):\n",
    "        m = X.shape[0]\n",
    "        dZ = activations[-1] - y\n",
    "        deltas = [dZ]\n",
    "        \n",
    "        for i in range(len(weights) - 1, 0, -1):\n",
    "            dZ = (deltas[-1] @ weights[i].T) * relu_derivative(Z_values[i - 1])\n",
    "            deltas.append(dZ)\n",
    "        \n",
    "        deltas.reverse()\n",
    "        \n",
    "        for i in range(len(weights)):\n",
    "            dW = (activations[i].T @ deltas[i]) / m\n",
    "            dB = np.sum(deltas[i], axis=0, keepdims=True) / m\n",
    "            \n",
    "            weights[i] -= lr * dW\n",
    "            biases[i] -= lr * dB\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        activations, Z_values = forward(X)\n",
    "        backward(activations, Z_values, Y)\n",
    "        if epoch % 10 == 0:\n",
    "            loss = -np.mean(Y * np.log(activations[-1] + 1e-8))\n",
    "            print(f\"Epoch {epoch}, Loss: {loss}\")\n",
    "\n",
    "    # Calculate Training Accuracy\n",
    "    y_train_pred = np.argmax(forward(X)[0][-1], axis=1)  \n",
    "    y_train_true = np.argmax(y, axis=1)  \n",
    "    train_accuracy = np.mean(y_train_pred == y_train_true)\n",
    "    print(f\"Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "    \n",
    "    # Calculate Test Accuracy\n",
    "    y_test_pred = np.argmax(forward(X_test)[0][-1], axis=1)  \n",
    "    y_test_true = np.argmax(y_test, axis=1)  \n",
    "    test_accuracy = np.mean(y_test_pred == y_test_true)\n",
    "    print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "    def predict(X_new):\n",
    "        activations, _ = forward(X_new)\n",
    "        return np.argmax(activations[-1], axis=1)\n",
    "\n",
    "    print(f\"Predicted Labels: {predict(X_test[:5])}\")\n",
    "\n",
    "layers = [784, 160, 100, 10]\n",
    "lr = 0.01\n",
    "epochs = 100\n",
    "ann(layers, lr, epochs, X, y, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
